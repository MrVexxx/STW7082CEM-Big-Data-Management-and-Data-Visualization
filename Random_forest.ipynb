{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqNl0eKWcnyj"
      },
      "outputs": [],
      "source": [
        "# 1. Import necessary libraries\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, when, sum\n",
        "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
        "from pyspark.ml.regression import LinearRegression, DecisionTreeRegressor, RandomForestRegressor\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.regression import RandomForestRegressor\n",
        "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3Jm_u10cuPm"
      },
      "outputs": [],
      "source": [
        "# 2. Initialize Spark Session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Crop Yield Prediction\") \\\n",
        "    .config(\"spark.executor.memory\", \"4g\") \\\n",
        "    .config(\"spark.driver.memory\", \"4g\") \\\n",
        "    .getOrCreate()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1HwoTWscuMu",
        "outputId": "3ced8886-4e50-4954-96dd-feb4da1bd2b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "# 3. Load dataset\n",
        "file_path = \"crop_yield.csv\"\n",
        "data = spark.read.csv(file_path, header=True, inferSchema=True)\n",
        "\n",
        "if data.count() > 0:\n",
        "    print(\"Dataset loaded successfully!\")\n",
        "else:\n",
        "    print(\"No data found in the dataset.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMx2wfG4cuJ2",
        "outputId": "4228ac53-b292-4d63-d9b5-55a7f5a39478"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Region: string (nullable = true)\n",
            " |-- Soil_Type: string (nullable = true)\n",
            " |-- Crop: string (nullable = true)\n",
            " |-- Rainfall_mm: double (nullable = true)\n",
            " |-- Temperature_Celsius: double (nullable = true)\n",
            " |-- Fertilizer_Used: boolean (nullable = true)\n",
            " |-- Irrigation_Used: boolean (nullable = true)\n",
            " |-- Weather_Condition: string (nullable = true)\n",
            " |-- Days_to_Harvest: integer (nullable = true)\n",
            " |-- Yield_tons_per_hectare: double (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Display dataset schema\n",
        "data.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiKW_EwRcuHW",
        "outputId": "77efba6c-cd70-45fe-e7a0-10bad62f28c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---------+-------+-----------------+-------------------+---------------+---------------+-----------------+---------------+----------------------+\n",
            "|Region|Soil_Type|   Crop|      Rainfall_mm|Temperature_Celsius|Fertilizer_Used|Irrigation_Used|Weather_Condition|Days_to_Harvest|Yield_tons_per_hectare|\n",
            "+------+---------+-------+-----------------+-------------------+---------------+---------------+-----------------+---------------+----------------------+\n",
            "|  West|    Sandy| Cotton|897.0772391101236| 27.676966373377603|          false|           true|           Cloudy|            122|     6.555816258223593|\n",
            "| South|     Clay|   Rice|992.6732816189208|  18.02614225436302|           true|           true|            Rainy|            140|       8.5273409063236|\n",
            "| North|     Loam| Barley|147.9980252926104|  29.79404241557257|          false|          false|            Sunny|            106|     1.127443335982929|\n",
            "| North|    Sandy|Soybean|986.8663313367325|  16.64419019137728|          false|           true|            Rainy|            146|     6.517572507555278|\n",
            "| South|     Silt|  Wheat| 730.379174445627| 31.620687370805797|           true|           true|           Cloudy|            110|     7.248251218445701|\n",
            "+------+---------+-------+-----------------+-------------------+---------------+---------------+-----------------+---------------+----------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Show the first few rows\n",
        "data.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HghDJzZ8cuEm",
        "outputId": "d7eaf5f9-111c-4e87-e629-915d9f89653a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Missing Values in Each Column:\n",
            "+------+---------+----+-----------+-------------------+---------------+---------------+-----------------+---------------+----------------------+\n",
            "|Region|Soil_Type|Crop|Rainfall_mm|Temperature_Celsius|Fertilizer_Used|Irrigation_Used|Weather_Condition|Days_to_Harvest|Yield_tons_per_hectare|\n",
            "+------+---------+----+-----------+-------------------+---------------+---------------+-----------------+---------------+----------------------+\n",
            "|     0|        0|   0|          0|                  0|              0|              0|                0|              0|                     0|\n",
            "+------+---------+----+-----------+-------------------+---------------+---------------+-----------------+---------------+----------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 4. Check for missing values\n",
        "print(\"\\nMissing Values in Each Column:\")\n",
        "missing_values = data.select(\n",
        "    [(sum(col(column).isNull().cast(\"int\")).alias(column)) for column in data.columns]\n",
        ")\n",
        "missing_values.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.select([\"Rainfall_mm\", \"Temperature_Celsius\", \"Days_to_Harvest\", \"Yield_tons_per_hectare\"]).describe().show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5fc2KhMIXNz",
        "outputId": "0dff2a0a-77ec-4012-eab6-6199d7296947"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+-------------------+------------------+----------------------+\n",
            "|summary|       Rainfall_mm|Temperature_Celsius|   Days_to_Harvest|Yield_tons_per_hectare|\n",
            "+-------+------------------+-------------------+------------------+----------------------+\n",
            "|  count|           1000000|            1000000|           1000000|               1000000|\n",
            "|   mean|  549.981900729366| 27.504965199661616|        104.495025|      4.64947248766303|\n",
            "| stddev|259.85132027823227|  7.220607587682008|25.953412277174294|     1.696572451116516|\n",
            "|    min|100.00089622522204| 15.000034141430271|                60|    -1.147613222534901|\n",
            "|    max|  999.998098221668|  39.99999662316004|               149|     9.963372228814649|\n",
            "+-------+------------------+-------------------+------------------+----------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.groupBy(\"Region\").count().show()\n",
        "data.groupBy(\"Soil_Type\").count().show()\n",
        "data.groupBy(\"Crop\").count().show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTDYoHSTIYKT",
        "outputId": "d245ea7a-0918-42cb-bcf8-ab3802bd7787"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+\n",
            "|Region| count|\n",
            "+------+------+\n",
            "| South|250054|\n",
            "|  East|249699|\n",
            "|  West|250074|\n",
            "| North|250173|\n",
            "+------+------+\n",
            "\n",
            "+---------+------+\n",
            "|Soil_Type| count|\n",
            "+---------+------+\n",
            "|    Sandy|167119|\n",
            "|     Loam|166795|\n",
            "|     Clay|166352|\n",
            "|   Chalky|166779|\n",
            "|     Silt|166672|\n",
            "|    Peaty|166283|\n",
            "+---------+------+\n",
            "\n",
            "+-------+------+\n",
            "|   Crop| count|\n",
            "+-------+------+\n",
            "|  Maize|166824|\n",
            "|Soybean|166349|\n",
            "|  Wheat|166673|\n",
            "| Cotton|166585|\n",
            "|   Rice|166792|\n",
            "| Barley|166777|\n",
            "+-------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HcdCq_lYxL3N"
      },
      "outputs": [],
      "source": [
        "# from pyspark.sql.functions import col\n",
        "# from pyspark.ml.stat import Correlation\n",
        "# from pyspark.ml.feature import VectorAssembler\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "\n",
        "# # Step 1: Select relevant numeric columns (ensure these columns exist in your dataset)\n",
        "# numeric_columns = [\n",
        "#     \"Rainfall_mm\", \"Temperature_Celsius\", \"Fertilizer_Used\",\n",
        "#     \"Irrigation_Used\", \"Days_to_Harvest\", \"Yield_tons_per_hectare\"\n",
        "# ]\n",
        "\n",
        "# # Step 2: Assemble features into a vector\n",
        "# assembler = VectorAssembler(inputCols=numeric_columns, outputCol=\"features\")\n",
        "# data_vector = assembler.transform(data).select(\"features\")\n",
        "\n",
        "# # Step 3: Compute the correlation matrix\n",
        "# correlation_matrix = Correlation.corr(data_vector, \"features\").head()[0].toArray()\n",
        "\n",
        "# # Step 4: Convert correlation matrix to a heatmap\n",
        "# plt.figure(figsize=(12, 10))\n",
        "# sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", cbar=True,\n",
        "#             xticklabels=numeric_columns, yticklabels=numeric_columns)\n",
        "# plt.title(\"Correlation Heatmap of Features (PySpark)\")\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9JHZvr0PcuB9"
      },
      "outputs": [],
      "source": [
        "# 5. Handle categorical columns using StringIndexer and OneHotEncoder\n",
        "categorical_columns = ['Region', 'Soil_Type', 'Crop', 'Weather_Condition']\n",
        "\n",
        "# 5.1 StringIndexer transformations\n",
        "indexers = [StringIndexer(inputCol=col, outputCol=col + \"_Index\").fit(data) for col in categorical_columns]\n",
        "for indexer in indexers:\n",
        "    data = indexer.transform(data)\n",
        "\n",
        "# Drop original categorical columns\n",
        "data = data.drop(*categorical_columns)\n",
        "\n",
        "# 5.2 One-hot encode the indexed columns\n",
        "encoder = OneHotEncoder(\n",
        "    inputCols=[col + \"_Index\" for col in categorical_columns],\n",
        "    outputCols=[col + \"_OHE\" for col in categorical_columns]\n",
        ")\n",
        "data = encoder.fit(data).transform(data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYGbCsNKct_W"
      },
      "outputs": [],
      "source": [
        "# 6. Assemble all features into a single vector\n",
        "feature_columns = [col for col in data.columns if col not in ['Yield_tons_per_hectare'] and not col.endswith('_Index')]\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
        "data = assembler.transform(data).select(\"features\", \"Yield_tons_per_hectare\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IP7G9Gl-ct8o"
      },
      "outputs": [],
      "source": [
        "# 7. Split data into training and testing sets\n",
        "train_data, test_data = data.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# 8. Train a Random Forest Regressor to extract feature importances\n",
        "rf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"Yield_tons_per_hectare\", numTrees=40)\n",
        "rf_model = rf.fit(train_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQNwj-Wcct6G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82fe6bd0-69c7-407f-c2d2-84320eb8353d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE (Random Forest Full Model) = 0.701\n",
            "R^2 (Random Forest Full Model)  = 0.829\n",
            "Mean Absolute Error (Random Forest Full Model) = 0.562\n",
            "Random Forest Model Accuracy = 82.86%\n"
          ]
        }
      ],
      "source": [
        "# ------------------------------------------\n",
        "# 9. Evaluate Random Forest Model Performance\n",
        "# ------------------------------------------\n",
        "predictions_rf = rf_model.transform(test_data)\n",
        "\n",
        "# Evaluate using RMSE\n",
        "evaluator_rf = RegressionEvaluator(\n",
        "    labelCol=\"Yield_tons_per_hectare\",\n",
        "    predictionCol=\"prediction\",\n",
        "    metricName=\"rmse\"\n",
        ")\n",
        "rmse_rf = evaluator_rf.evaluate(predictions_rf)\n",
        "\n",
        "# Evaluate using R²\n",
        "r2_rf = RegressionEvaluator(\n",
        "    labelCol=\"Yield_tons_per_hectare\",\n",
        "    predictionCol=\"prediction\",\n",
        "    metricName=\"r2\"\n",
        ").evaluate(predictions_rf)\n",
        "\n",
        "print(f\"RMSE (Random Forest Full Model) = {rmse_rf:.3f}\")\n",
        "print(f\"R^2 (Random Forest Full Model)  = {r2_rf:.3f}\")\n",
        "\n",
        "# 9.1 Calculate and Display Random Forest Model Accuracy\n",
        "# ------------------------------------------\n",
        "# Use Mean Absolute Error (MAE) as another metric\n",
        "mae_rf = RegressionEvaluator(\n",
        "    labelCol=\"Yield_tons_per_hectare\",\n",
        "    predictionCol=\"prediction\",\n",
        "    metricName=\"mae\"\n",
        ").evaluate(predictions_rf)\n",
        "\n",
        "# Calculate accuracy percentage (R^2 * 100 for interpretability)\n",
        "accuracy_percentage_rf = r2_rf * 100\n",
        "\n",
        "print(f\"Mean Absolute Error (Random Forest Full Model) = {mae_rf:.3f}\")\n",
        "print(f\"Random Forest Model Accuracy = {accuracy_percentage_rf:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add residuals for Random Forest predictions\n",
        "predictions_rf = predictions_rf.withColumn(\"Residuals\", col(\"Yield_tons_per_hectare\") - col(\"prediction\"))\n",
        "\n",
        "# Select relevant columns for export\n",
        "export_rf = predictions_rf.select(\"Yield_tons_per_hectare\", \"prediction\", \"Residuals\")\n",
        "\n",
        "# Export to CSV\n",
        "export_rf.coalesce(1).write.csv(\"random_forest.csv\", header=True, mode=\"overwrite\")\n",
        "print(\"Random Forest predictions exported successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pb8W56RWOuj9",
        "outputId": "785c6327-7322-4fca-e167-73e80e196d77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest predictions exported successfully!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}